| # | Database     | Open-Source | License            | Hosting Choices                  | Core Lang              | Vector Index Types                                                | Distance Metrics                     | Search Modes (Semantic + Other)                                            | Max Vectors (prod) | p99 Latency (1 M) | QPS (1 M) | Recall\@30 | Free Tier         | Cost Mood (USD)                                   | Best At                            | Ops Over-head | Lock-in Risk | Extra / Unique Capabilities                                                      | **Our Suggestion / When to Pick It**                                                                                                                       |
| - | ------------ | ----------- | ------------------ | -------------------------------- | ---------------------- | ----------------------------------------------------------------- | ------------------------------------ | -------------------------------------------------------------------------- | ------------------ | ----------------- | --------- | ---------- | ----------------- | ------------------------------------------------- | ---------------------------------- | ------------- | ------------ | -------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1 | **Pinecone** | ❌           | Proprietary        | SaaS only                        | —                      | HNSW + proprietary                                                | Cosine, Euclidean, Dot               | Dense ANN, Sparse BM25, Hybrid alpha, Metadata pre-filter                  | ~2 B               | 7–26 ms           | 85        | 98 %       | ❌                 | $ $ \$ <br>(\$0.10/k queries, ≈\$100/m per M vec) | Zero-ops RAG, SOC-2                | Zero          | High         | Auto-sharding, real-time updates, RBAC, 99.9 % SLA                               | **Choose when you need the quickest time-to-prod**, have < 50 M vectors, and ops budget is near-zero.                                                      |
| 2 | **Milvus**   | ✅           | Apache 2.0         | Self-managed / Zilliz Cloud      | Go / C++               | HNSW, IVF, SCANN, GPU-CAGRA, Disk-ANN, PQ, IVF-SQ8                | Cosine, L2, IP, Hamming, Jaccard     | Dense, Sparse (SPLADE, BGE-M3), Range, Multi-vector re-rank, Scalar filter | 5 B+               | 20–75 ms          | 170       | 99 %       | 1 GB cloud        | $ $ <br>(self-host free, Zilliz ≈\$45/m per M)    | Billion-scale, GPU accel           | High          | Low          | GPU index 5× faster, k8s operator, LDAP, audit, multi-tenant RBAC                | **Pick if you expect > 100 M vectors or need GPU/CPU mixed clusters**; tolerate k8s ops.                                                                   |
| 3 | **Qdrant**   | ✅           | Apache 2.0         | Docker / K8s / Qdrant Cloud      | Rust                   | HNSW (SIMD), Quantization (Binary, Scalar, Product), Sparse index | Cosine, Euclidean, Dot, Manhattan    | Dense, Sparse BM25-like, Geo-radius, Payload filter, Multi-collection      | 100 M / node       | 1–39 ms           | 626       | 98 %       | 1 GB forever      | \$ <br>(cloud \$25/m 5 GB, self-host free)        | Edge, rich filters, lean RAM       | Low           | Low          | Rust SIMD engine, 50 MB edge binary, snapshot backup, distributed mode           | **Default for startups & edge**: cheap, fast, filter-heavy, runs on a laptop or a cluster.                                                                 |
| 4 | **Weaviate** | ✅           | BSD-like           | Docker / K8s / WCS               | Go                     | HNSW (PQ roadmap)                                                 | Cosine, L2, Dot                      | Dense ANN, BM25 text, Hybrid alpha, Multi-modal (text+image)               | 100 M              | 50–100 ms         | 250       | 98 %       | 14-day sandbox    | $ $ <br>(WCS ≈\$100/m per M)                      | Built-in vectorizers, GraphQL      | Medium        | Medium       | Modules (CLIP, Transformers), semantic back-ups, k8s Helm, multi-tenant          | **Use when you want GraphQL APIs or built-in ML vectorizers** without wiring your own.                                                                     |
| 5 | **pgvector** | ✅           | PostgreSQL License | Any Postgres host                | C                      | IVFFlat, HNSW, DiskANN (pgvectorscale)                            | L2, Cosine, IP, L1                   | Dense ANN + SQL filters, joins, range radius, hybrid full-text             | 100 M+             | 28–75 ms          | 471       | 99 %       | ✅ (OSS)           | \$ <br>(infra only, RDS ≈\$15/m small)            | Unified SQL stack, ACID            | Medium        | Zero         | Row-level security, backups, replication, no extra cluster                       | **Obvious pick if you already run Postgres**—adds vectors without new infra.                                                                               |
| 6 | **ChromaDB** | ✅           | Apache 2.0         | Embedded / Docker / Chroma Cloud | Python / Rust (engine) | HNSW (Rust), Quantization (2025)                                  | Cosine, L2, Dot                      | Dense ANN, Built-in metadata & full-text, Auto-embedding                   | < 10 M rec.        | 40–90 ms          | 120       | 97 %       | \$5 cloud credits | \$ <br>(local free, cloud ~\$20/m per M)          | Prototypes, RAG MVPs, LangChain    | Very Low      | Low          | NumPy-like API, offline embedded mode, 4× faster after Rust rewrite              | **Perfect for day-0 prototypes, Jupyter notebooks, or CI tests**; swap out later when scale hits.                                                          |
| 7 | **Vespa**    | ✅           | Apache 2.0         | Self-hosted / Vespa Cloud        | Java / C++             | HNSW, Tensor, BM25, custom ranking                                | Cosine, L2, Dot, Angular, Tensor ops | Dense ANN, Sparse BM25, Tensor, Structured filters, Grouping/aggregation   | 10 B+              | 30–80 ms          | 300       | 99 %       | ✅ (OSS)           | $ $ <br>(self-host free, cloud ≈\$60/m per M)     | Hybrid big-data, real-time ranking | High          | Low          | Real-time writes 10 k+/node/s, redundancy config, custom ML scoring, multi-modal | **Choose when you need heavy hybrid (text + vector + structured) at web-scale**, e.g. search engine or ad-tech, and you can afford the ops learning curve. |


## QPS (1 M)
Queries Per Second : nombre de requêtes de similarité que la base peut servir par seconde sur un corpus de 1 million de vecteurs.
Plus le chiffre est élevé, plus la base supporte un fort trafic simultané.
## Rappel@30
Recall@30 : parmi les 30 voisins les plus proches du résultat parfait, quelle proportion la base retourne-t-elle vraiment ?
Exprimé en % ; plus proche de 100 % = moins de faux absents.
## p99
99-th percentile latency : temps de réponse dans le pire des cas pour 99 % des requêtes (1 % restantes peuvent être plus lentes).
Plus le chiffre est faible, plus la latence est stable sous charge.
