| # | Base de données | Open-Source | Licence            | Options d'hébergement             | Langage principal      | Types d'index vectoriels                   | Métriques de distance                  | Modes de recherche (sémantique + autres)                                    | Max Vectors (prod) | Latence p99 (1 M) | QPS (1 M) | Rappel\@30 | Free Tier             | Coût (USD)                                            | Excellente pour                      | Charge opérationnelle | Risque de lock-in | Capacités uniques                                                                          | ** conseil / Quand la choisir**                                                                                                                                                     |
| - | --------------- | ----------- | ------------------ | --------------------------------- | ---------------------- | ------------------------------------------ | -------------------------------------- | --------------------------------------------------------------------------- | ------------------ | ----------------- | --------- | ---------- | --------------------- | ----------------------------------------------------- | ------------------------------------ | --------------------- | ----------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1 | **Pinecone**    | ❌           | Propriétaire       | SaaS uniquement                   | —                      | HNSW + propr.                              | Cosinus, Euclidien, Dot                | ANN dense, BM25 sparse, Hybride alpha, filtre métadonnées                   | ~2 Mds             | 7–26 ms           | 85        | 98 %       | ❌                     | $ $ $<br>(≈100$/mois par M vec)                       | RAG sans ops, SOC-2                  | Zéro                  | Élevé             | Shard. auto, mises à jour temps réel, RBAC, SLA 99,9 %                                     | **Choisissez pour un time-to-prod ultra-rapide**, < 50 M de vecteurs, budget ops nul.                                                                                                    |
| 2 | **Milvus**      | ✅           | Apache 2.0         | Self / Zilliz Cloud               | Go / C++               | HNSW, IVF, SCANN, GPU-CAGRA, Disk-ANN, PQ… | Cosinus, L2, IP, Hamming, Jaccard      | Dense, sparse (SPLADE, BGE-M3), range, multi-vector, filtre scalaire        | 5 Mds+             | 20–75 ms          | 170       | 99 %       | 1 GB cloud            | $ $ <br>(self-host gratuit, Zilliz ≈45 \$/mois par M) | Milliard-scale, accélération GPU     | Élevée                | Faible            | Index GPU 5× plus rapide, opérateur k8s, LDAP, audit, RBAC multi-locataire                 | **Prenez-la si vous dépassez 100 M vecteurs ou si vous avez besoin de GPU**; acceptez la complexité k8s.                                                                                 |
| 3 | **Qdrant**      | ✅           | Apache 2.0         | Docker / K8s / Cloud              | Rust                   | HNSW (SIMD), quantification, sparse index  | Cosinus, Euclidien, Dot, Manhattan     | Dense, sparse BM25-like, geo-radius, filtre payload, multi-collection       | 100 M / nœud       | 1–39 ms           | 626       | 98 %       | 1 GB à vie            | $<br>(cloud 25$/5 GB, self-host gratuit)              | Edge, filtres riches, RAM légère     | Faible                | Faible            | Moteur Rust SIMD, binaire 50 MB, sauvegarde instantanée, mode distribué                    | **Default pour start-ups & edge** : pas cher, rapide, filtre dense, tourne sur laptop ou cluster.                                                                                        |
| 4 | **Weaviate**    | ✅           | BSD-like           | Docker / K8s / WCS                | Go                     | HNSW (PQ roadmap)                          | Cosinus, L2, Dot                       | ANN dense, BM25 texte, hybride alpha, multi-modal (texte+image)             | 100 M              | 50–100 ms         | 250       | 98 %       | Bac à sable 14 j      | $ $ <br>(WCS ≈100 \$/mois par M)                      | Vectoriseurs intégrés, GraphQL       | Moyenne               | Moyenne           | Modules (CLIP, Transformers), sauvegardes sémantiques, Helm k8s, multi-locataire           | **Utilisez quand vous voulez GraphQL ou des vectoriseurs ML built-in** sans les coder.                                                                                                   |
| 5 | **pgvector**    | ✅           | Licence PostgreSQL | N’importe quel hébergeur Postgres | C                      | IVFFlat, HNSW, DiskANN (pgvectorscale)     | L2, Cosinus, IP, L1                    | ANN dense + filtres SQL, jointures, rayon de portée, full-text hybride      | 100 M+             | 28–75 ms          | 471       | 99 %       | ✅ (OSS)               | $<br>(infra uniquement, RDS ≈15$/mois small)          | Stack SQL unifié, ACID               | Moyenne               | Zéro              | Sécurité niveau ligne, sauvegardes, réplication, pas de cluster supplémentaire             | **Choix évident si vous avez déjà Postgres** → ajoute les vecteurs sans nouvelle infra.                                                                                                  |
| 6 | **ChromaDB**    | ✅           | Apache 2.0         | Embedded / Docker / Cloud         | Python / Rust (moteur) | HNSW (Rust), quantification (2025)         | Cosinus, L2, Dot                       | ANN dense, métadonnées & full-text intégrés, auto-embedding                 | < 10 M enr.        | 40–90 ms          | 120       | 97 %       | 5 \$ de crédits cloud | $<br>(local gratuit, cloud ~20$/mois par M)           | Prototypes, RAG MVPs, LangChain      | Très faible           | Faible            | API style NumPy, mode embedded hors ligne, 4× plus rapide après rewrite Rust               | **Parfait pour les prototypes day-0, notebooks Jupyter ou tests CI** ; changez quand l’échelle augmente.                                                                                 |
| 7 | **Vespa**       | ✅           | Apache 2.0         | Self-hosted / Vespa Cloud         | Java / C++             | HNSW, Tensor, BM25, ranking personnalisé   | Cosinus, L2, Dot, Angular, ops tenseur | ANN dense, BM25 sparse, Tensor, filtres structurés, regroupement/agrégation | 10 Mds+            | 30–80 ms          | 300       | 99 %       | ✅ (OSS)               | $ $ <br>(self-host gratuit, cloud ≈60 \$/mois par M)  | Big-data hybride, ranking temps réel | Élevée                | Faible            | Écritures temps réel 10 k+/nœud/s, config redondante, scoring ML personnalisé, multi-modal | **Choisissez quand vous avez besoin d’hybride lourd (texte + vecteur + structuré)** à échelle web (ex. moteur de recherche, ad-tech) et que vous acceptez la courbe d’apprentissage ops. |



## QPS (1 M)
Queries Per Second : nombre de requêtes de similarité que la base peut servir par seconde sur un corpus de 1 million de vecteurs.
Plus le chiffre est élevé, plus la base supporte un fort trafic simultané.
## Rappel@30
Recall@30 : parmi les 30 voisins les plus proches du résultat parfait, quelle proportion la base retourne-t-elle vraiment ?
Exprimé en % ; plus proche de 100 % = moins de faux absents.
## p99
99-th percentile latency : temps de réponse dans le pire des cas pour 99 % des requêtes (1 % restantes peuvent être plus lentes).
Plus le chiffre est faible, plus la latence est stable sous charge.
